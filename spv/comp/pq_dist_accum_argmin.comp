#version 450
layout(local_size_x = 256) in;

/*
PQ_DIST + ARGMIN PARTIAL:
dist[i] = sum_m lut[m*Ks + code[i*M + m]]
partials[group] = (best_dist, best_index) for this group
Deterministic per workgroup via fixed-order reduction.
*/

layout(std430, set=0, binding=0) readonly buffer LUT { float lut[]; };     // M*Ks
layout(std430, set=0, binding=1) readonly buffer CODES { uint codes[]; };  // Nvec*M (each in 0..Ks-1)
layout(std430, set=0, binding=2) writeonly buffer DIST { float dist[]; };  // Nvec
layout(std430, set=0, binding=3) writeonly buffer PART { uvec2 partials[]; };
// partials[group] = (best_index, floatBitsToUint(best_dist))

layout(push_constant) uniform PC {
  uint Nvec;
  uint M;
  uint Ks;
} pc;

shared float sh_val[256];
shared uint  sh_idx[256];

void main() {
  uint i = gl_GlobalInvocationID.x;
  uint lid = gl_LocalInvocationID.x;

  float dacc = 3.402823e38; // +FLT_MAX
  uint idx = i;

  if (i < pc.Nvec) {
    float s = 0.0;
    uint base = i * pc.M;
    for (uint m = 0u; m < pc.M; m++) {
      uint c = codes[base + m];
      // assume c < Ks; host should ensure
      s += lut[m * pc.Ks + c];
    }
    dacc = s;
    dist[i] = s;
  }

  sh_val[lid] = dacc;
  sh_idx[lid] = idx;
  barrier();

  // deterministic argmin reduction: tie-break by smaller index
  for (uint stride = 128; stride > 0; stride >>= 1) {
    if (lid < stride) {
      float v0 = sh_val[lid];
      float v1 = sh_val[lid + stride];
      uint  i0 = sh_idx[lid];
      uint  i1 = sh_idx[lid + stride];

      bool take1 = (v1 < v0) || (v1 == v0 && i1 < i0);
      if (take1) {
        sh_val[lid] = v1;
        sh_idx[lid] = i1;
      }
    }
    barrier();
  }

  if (lid == 0) {
    // pack as uvec2(best_index, best_dist_bits)
    partials[gl_WorkGroupID.x] = uvec2(sh_idx[0], floatBitsToUint(sh_val[0]));
  }
}
